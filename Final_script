# -*- coding: utf-8 -*-
"""finalsubmission (2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tXL-HVg4Ubp8L6JZhgpLyk35zUuuW_AT
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from sklearn.preprocessing import OrdinalEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import AdaBoostClassifier
from sklearn.decomposition import PCA
import datetime

class submission:
    def __init__(self, xtrain, ytrain, xtest):
        self.train_x = xtrain
        self.train_y = ytrain
        self.test_x = xtest
    
    def create_submission(self,clf):
        classifier = clf
        enc = OrdinalEncoder()
        x_train_enc_cols = pd.DataFrame(enc.fit_transform(self.train_x[['biker_id', 'tour_id']]), columns=['biker_id', 'tour_id'])
        x_train_enc = self.train_x.copy()
        x_train_enc['biker_id'] = x_train_enc_cols['biker_id']
        x_train_enc['tour_id'] = x_train_enc_cols['tour_id']
        classifier.fit(x_train_enc, self.train_y)
        x_enc_cols = pd.DataFrame(enc.fit_transform(self.test_x[['biker_id', 'tour_id']]), columns=['biker_id', 'tour_id'])
        x_enc = self.test_x.copy()
        x_enc['biker_id'] = x_enc_cols['biker_id']
        x_enc['tour_id'] = x_enc_cols['tour_id']
        x = self.test_x.copy()
        ypred = pd.Series(classifier.predict(x_enc),name='ypred')
        ans = pd.concat([x,ypred],axis=1)
        sub = []
        np.random.seed(1)
        for biker in x.biker_id.drop_duplicates():
            like_tours = ans.tour_id[np.logical_and(ans.biker_id==biker, ans.ypred==1)].to_numpy()
            np.random.shuffle(like_tours)
            dislike_tours = ans.tour_id[np.logical_and(ans.biker_id==biker, ans.ypred==0)].to_numpy()
            np.random.shuffle(dislike_tours)
            temp = [biker, " ".join(like_tours.tolist()+dislike_tours.tolist())]
            sub.append(temp)
        final_sub = pd.DataFrame(data=sub,columns=['biker_id','tour_id'])
        return final_sub
    
#func used to convert time

def conv_to_time(a):
    my_string = a
    b = datetime.datetime.strptime(my_string, '%d-%m-%Y %H:%M:%S')
    c = datetime.datetime.timestamp(b)
    return c


#func used to impute

def find_score(biker,tour):
    org = tours_mod['biker_id'][tour]           

        
    #friedns of bikers
    if type(network['friends'][biker]) == str:
        temp1 = network['friends'][biker].split(" ")
    else:
        temp1 = []

            
    
    #names of bikers not going to the given tour
    if type(convoy['not_going'][tour]) == str:
        temp2 = convoy['not_going'][tour].split(" ")
    else:
        temp2 = []
    
    #names of bikers going to the given tour
    if type(convoy['going'][tour]) == str:
        temp3 = convoy['going'][tour].split(" ")
    else:
        temp3 = []
    
    #names of bikers invited to the tour
    inv_flag = False
    if convoy['invited'][tour] == 'str':
        invitees = invitees.split(" ")
        inv_flag = True
    
    
    score = 0
    for i in range(len(temp1)):
        if temp1[i] in temp3:             #friends of given biker going to the given tour
            score += 2
        if temp1[i] in temp2:             #friends of given biker not going to the given tour
            score -= 2
        if inv_flag and temp[i] in invitees:     #friends of given biker invited to the given tour
            score += 1
    

    if score < 0:
        return np.sign(score)
    else:
        if org in temp1:                  #if organizer is biker's friend
            return 1


        bik_area = bikers['area'][biker]   #if tour is in the same area as the biker
        if org in bikers.index:
            tou_area = bikers['area'][org]
            if bik_area == tou_area:
                return 1
        
        #other tours the biker has rated 
        other_rats = train_present[train_present['biker_id'] == biker]
        if len(other_rats != 0):
            score_ = 0
            for j in range(len(other_rats)):
                if type(convoy['not_going'][other_rats['tour_id'][other_rats.index[j]]]) == str:
                    temp2 = convoy['not_going'][other_rats['tour_id'][other_rats.index[j]]].split(" ")
                else:
                    temp2 = []

                if type(convoy['going'][other_rats['tour_id'][other_rats.index[j]]]) == str:
                    temp3 = convoy['going'][other_rats['tour_id'][other_rats.index[j]]].split(" ")
                else:
                    temp3 = []


                for i in range(len(temp1)):
                    if temp1[i] in temp3:
                        score_ += 2
                    if temp1[i] in temp2:
                        score_ -= 2
                        
            if score_ < 0:
                return np.sign(score_)
            else:
                return 0
        else:
            return 0
            
        



# Imputation
path = '/data'  # path for the data sets

#bikers
bikers = pd.read_csv(path+"/bikers.csv")
bikers = bikers.set_index('biker_id')
bikers = bikers.drop(columns = ["language_id",'location_id','time_zone','gender','bornIn','member_since'])

#network 
network = pd.read_csv(path+"/bikers_network.csv")
network = network.set_index('biker_id')

#tour convoy
convoy = pd.read_csv(path+"/tour_convoy.csv").set_index("tour_id")

#tours
tours = pd.read_csv(path+"/tours.csv")
tours = tours.rename(columns = {"w_other":"w101"})

#test
test = pd.read_csv(path+"/test.csv")

#train
train = pd.read_csv(path+"/train.csv")

train_copy = train.copy()

# Checking the datasets
#invite == 1
for i in range(len(train_copy)):
    if train_copy['invited'][i] == 1:
        if train_copy['like'][i] == 0 and train_copy['dislike'][i] == 0:
            train_copy['like'][i] = 1
            train_copy['dislike'][i] = 0
            

Y_train = np.empty(train_copy.shape[0]).reshape(-1,1)
temp1 = train_copy['like'].to_numpy()
temp2 = train_copy['dislike'].to_numpy()
for i in range(train_copy.shape[0]):
    if temp1[i] == 1:
        Y_train[i] = 1
    elif temp2[i] == 1:
        Y_train[i] = -1
    else:
        Y_train[i] = 0
               
train_copy.insert(len(train_copy.columns),'like/dislike',Y_train.astype(int))
train_copy = train_copy.drop(columns = ['like','dislike'])

train_missing = train_copy[train_copy['like/dislike'] == 0]
train_present = train_copy[train_copy['like/dislike'] != 0]


# PCA on tours 
tours_cols = list(tours.columns)
tours_cols = tours_cols[9:]
w = tours[tours_cols]

w_num = w['w1'].to_numpy().reshape(-1,1)
for i in range(1,101):
    w_num = np.append(w_num,w['w{}'.format(i+1)].to_numpy().reshape(-1,1),axis=1)

n_comps = 2
pca = PCA(n_components=n_comps)
pca.fit(w_num)

w_pca_2 = pca.transform(w_num)
temp2 = pd.DataFrame(w_pca_2,columns=['w1p', 'w2p'])
tours_cols_ = list(tours.columns)
tours_cols_ = tours_cols_[:9]
temp1 = tours[tours_cols_]
tours_mod = pd.concat([temp1, temp2], axis=1)
tours_mod = tours_mod.rename(columns = {"x1p":"w1p","x2p":'w2p'}).set_index('tour_id')

#iterating through train_missing imputing missing values using the above func
for i in train_missing.index:
#     print(train_missing['tour_id'][i], train_missing['biker_id'][i])
    curr_tour = train_missing['tour_id'][i]
    curr_biker = train_missing['biker_id'][i]
    train_missing['like/dislike'][i] = find_score(curr_biker,curr_tour)

train_missing = train_missing[train_missing['like/dislike']!=0]
train_imputed = pd.concat([train_present, train_missing], axis=0)


# Running the classifier and making the submission on the imputed data

train4 = train_imputed
train['like/dislike'] = train['like']
train_final = pd.concat([train.loc[train['like/dislike']==1,:], train4.loc[train4['like/dislike']==-1,:]],axis=0)

x_t = train_final.drop(columns=['like/dislike', 'like', 'dislike']).reset_index(drop=True)
y_t = train_final['like/dislike'].copy().reset_index(drop=True)

x_t.timestamp = x_t.timestamp.apply(conv_to_time)
x_t.timestamp = (x_t.timestamp-x_t.timestamp.mean())/x_t.timestamp.std()
y_t[y_t==-1] = 0

clf = AdaBoostClassifier(base_estimator=LogisticRegression())
xtrain = x_t
ytrain = y_t
test.timestamp = test.timestamp.apply(conv_to_time)
test.timestamp = (test.timestamp - test.timestamp.mean())/test.timestamp.std()
sub_ = submission(xtrain, ytrain, test)
subm = sub_.create_submission(clf)
subm.to_csv('submission.csv', header=True, index=False)